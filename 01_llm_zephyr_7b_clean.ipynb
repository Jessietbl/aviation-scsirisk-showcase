{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jessietbl/aviation-scsirisk-showcase/blob/main/01_llm_zephyr_7b_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM-based Trade Data Extraction (Zephyr-7B) — Showcase\n",
        "\n",
        "This demo extracts **monthly trade statistics** (exports, imports, trade_balance, total_trade) from Malaysian trade bulletins.\n",
        "\n",
        "**What’s inside**\n",
        "1) Load PDFs from `inputs/`  \n",
        "2) Extract & clean text  \n",
        "3) Prompt Zephyr-7B for JSON  \n",
        "4) Parse + (optionally) benchmark vs ground truth\n",
        "\n",
        "> Uses **sample PDFs / sample GT** only. Full thesis data/code remain private.\n"
      ],
      "metadata": {
        "id": "ZrU_M4UEfj5e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6W2L3wlfb6r"
      },
      "outputs": [],
      "source": [
        "# --- 0. Imports & Config (portable: no !pip, no Colab APIs) ---\n",
        "from pathlib import Path\n",
        "import os, re, json, glob, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pdfplumber\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "from src.utils import (\n",
        "    preprocess_text,\n",
        "    build_llm_prompt,\n",
        "    parse_llm_output,\n",
        "    coerce_billion,\n",
        "    metrics_table\n",
        ")\n",
        "\n",
        "INPUT_DIR = Path(\"inputs\")          # put sample PDFs here\n",
        "OUT_DIR   = Path(\"outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "GT_CSV    = Path(\"data/sample_ground_truth.csv\")  # optional benchmark\n",
        "MODEL_ID  = \"HuggingFaceH4/zephyr-7b-beta\"  # keep as-is for clarity\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p src\n"
      ],
      "metadata": {
        "id": "ptFU7v1bk2cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "import re, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------- text cleanup ----------\n",
        "def preprocess_text(text: str) -> str:\n",
        "    \"\"\"Light, OCR-aware normalization for bulletin text.\"\"\"\n",
        "    t = re.sub(r\"\\s+\", \" \", (text or \"\").strip())\n",
        "\n",
        "    # Common OCR & currency fixes\n",
        "    t = re.sub(r\"RlVl\", \"RM\", t)\n",
        "    t = re.sub(r\"R[Mm]\", \"RM\", t)\n",
        "\n",
        "    # Spelling variants\n",
        "    t = re.sub(r\"\\b[bil]{1,2}ion\\b\", \"billion\", t, flags=re.I)\n",
        "    t = re.sub(r\"\\bmill[il]on\\b\", \"million\", t, flags=re.I)\n",
        "\n",
        "    # 123,456 → 123456 (but leave decimals)\n",
        "    t = re.sub(r\"(?<=\\d),(?=\\d{3}\\b)\", \"\", t)\n",
        "\n",
        "    # normalize currency wording\n",
        "    t = re.sub(r\"ringgit\\s+malaysia\", \"RM\", t, flags=re.I)\n",
        "    t = re.sub(r\"rm\\s*(billion|million)\", r\"RM \\1\", t, flags=re.I)\n",
        "    return t\n",
        "\n",
        "\n",
        "# ---------- prompt ----------\n",
        "def build_llm_prompt(text: str, filename: str) -> str:\n",
        "    return f\"\"\"\n",
        "<s>[INST] You are an assistant extracting Malaysian monthly trade values.\n",
        "\n",
        "TASK:\n",
        "- Extract ONLY the **latest month** mentioned.\n",
        "- Units: **RM BILLIONS** (millions ÷ 1,000; trillions × 1,000).\n",
        "- Return **JSON only** with keys: exports, imports, trade_balance, total_trade.\n",
        "- Use null for missing/uncertain fields.\n",
        "\n",
        "SOURCE_FILE: {filename}\n",
        "BULLETIN_TEXT:\n",
        "{text}\n",
        "[/INST]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# ---------- robust JSON parsing ----------\n",
        "def parse_llm_output(raw: str) -> dict | None:\n",
        "    \"\"\"\n",
        "    Extract the first valid JSON-looking object and coerce fields.\n",
        "    \"\"\"\n",
        "    if not raw:\n",
        "        return None\n",
        "\n",
        "    # find the outermost {...}\n",
        "    matches = re.findall(r\"\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}\", raw, flags=re.DOTALL)\n",
        "    for m in matches:\n",
        "        try:\n",
        "            data = json.loads(m)\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "        out = {}\n",
        "        for k in [\"exports\", \"imports\", \"trade_balance\", \"total_trade\"]:\n",
        "            v = data.get(k, None)\n",
        "            try:\n",
        "                out[k] = float(v) if v is not None else None\n",
        "            except Exception:\n",
        "                out[k] = None\n",
        "        return out\n",
        "    return None\n",
        "\n",
        "\n",
        "# ---------- unit coercion ----------\n",
        "def coerce_billion(x) -> float | None:\n",
        "    \"\"\"Normalize values to RM **billions**.\"\"\"\n",
        "    if x is None:\n",
        "        return None\n",
        "    try:\n",
        "        v = float(str(x).replace(\",\", \"\"))\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "    # if way too large, guess units and convert\n",
        "    if v > 2_000_000_000:   # raw RM\n",
        "        v /= 1_000_000_000\n",
        "    elif v > 2_000_000:     # millions\n",
        "        v /= 1_000\n",
        "    return float(v)\n",
        "\n",
        "\n",
        "# ---------- metrics table ----------\n",
        "def _metrics(y, yhat):\n",
        "    y = np.asarray(y, float)\n",
        "    yhat = np.asarray(yhat, float)\n",
        "    mask = np.isfinite(y) & np.isfinite(yhat)\n",
        "    if mask.sum() == 0:\n",
        "        return dict(MAE=np.nan, RMSE=np.nan, R2=np.nan)\n",
        "    y, yhat = y[mask], yhat[mask]\n",
        "    mae  = np.mean(np.abs(yhat - y))\n",
        "    rmse = np.sqrt(np.mean((yhat - y) ** 2))\n",
        "    denom = np.sum((y - y.mean()) ** 2)\n",
        "    r2 = 1 - np.sum((yhat - y) ** 2) / denom if denom > 1e-12 else np.nan\n",
        "    return dict(MAE=mae, RMSE=rmse, R2=r2)\n",
        "\n",
        "def metrics_table(df: pd.DataFrame, keys: list[str]) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    for k in keys:\n",
        "        pred = df.get(k)\n",
        "        true = df.get(f\"{k}_true\")\n",
        "        if pred is None or true is None:\n",
        "            continue\n",
        "\n",
        "        # light outlier guard (3×IQR on abs error)\n",
        "        e = (pred - true).astype(float)\n",
        "        q1, q3 = np.nanpercentile(np.abs(e), [25, 75])\n",
        "        thr = q3 + 3 * (q3 - q1)\n",
        "        mask = (np.abs(e) <= thr) | ~np.isfinite(e)\n",
        "\n",
        "        sc = _metrics(true[mask], pred[mask])\n",
        "        rows.append({\"Metric\": k.title(), **{k: round(v, 3) if v == v else np.nan for k, v in sc.items()}})\n",
        "    return pd.DataFrame(rows).set_index(\"Metric\")\n"
      ],
      "metadata": {
        "id": "uHz42az-k4K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. PDF → text (OCR fallback) ---\n",
        "MONTH_RE = re.compile(\n",
        "    r\"\\b(January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4}\\b\",\n",
        "    flags=re.I\n",
        ")\n",
        "\n",
        "def extract_text_enhanced(path: Path, max_pages: int = 6) -> str:\n",
        "    \"\"\"\n",
        "    Extract text from first few content pages; fallback to OCR when needed.\n",
        "    Filters to pages that likely mention the current month.\n",
        "    \"\"\"\n",
        "    text = []\n",
        "    with pdfplumber.open(path) as pdf:\n",
        "        pages = pdf.pages[1:max_pages+1] if len(pdf.pages) > 1 else pdf.pages\n",
        "        for idx, page in enumerate(pages, start=2):\n",
        "            raw = page.extract_text() or \"\"\n",
        "            if len(raw.strip()) < 60 or (\"export\" not in raw.lower() and \"trade\" not in raw.lower()):\n",
        "                try:\n",
        "                    image = page.to_image(resolution=300).original\n",
        "                    raw = pytesseract.image_to_string(image, lang=\"eng\", config=\"--psm 6 --oem 3\")\n",
        "                except Exception:\n",
        "                    raw = \"\"\n",
        "            if raw and MONTH_RE.search(raw):\n",
        "                text.append(f\"\\n--- PAGE {idx} ---\\n{raw}\")\n",
        "\n",
        "        # fallback: if nothing caught the month, just append raw text\n",
        "        if not \"\".join(text).strip():\n",
        "            for idx, page in enumerate(pages, start=2):\n",
        "                raw = page.extract_text() or \"\"\n",
        "                if raw:\n",
        "                    text.append(f\"\\n--- PAGE {idx} ---\\n{raw}\")\n",
        "\n",
        "    return preprocess_text(\"\\n\".join(text))[:8000]\n"
      ],
      "metadata": {
        "id": "Pkt3upcefoJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Load Zephyr-7B (4-bit optional to keep VRAM small) ---\n",
        "def load_llm(model_id: str = MODEL_ID):\n",
        "    qconf = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=\"bfloat16\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "    )\n",
        "    tok = AutoTokenizer.from_pretrained(model_id)\n",
        "    tok.pad_token = tok.eos_token\n",
        "    mdl = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id, device_map=\"auto\", quantization_config=qconf, trust_remote_code=True\n",
        "    )\n",
        "    return pipeline(\n",
        "        \"text-generation\",\n",
        "        model=mdl,\n",
        "        tokenizer=tok,\n",
        "        return_full_text=False,\n",
        "        pad_token_id=tok.eos_token_id,\n",
        "    )\n",
        "\n",
        "pipe = load_llm()\n"
      ],
      "metadata": {
        "id": "BtRtZHhsfsRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Single-file extraction (PDF → text → LLM JSON → dict) ---\n",
        "def extract_llm_only(pdf_path: Path) -> dict | None:\n",
        "    fname = pdf_path.name\n",
        "    txt = extract_text_enhanced(pdf_path)\n",
        "    if not txt or len(txt) < 120:\n",
        "        return None\n",
        "\n",
        "    prompt = build_llm_prompt(txt, fname)\n",
        "    raw = pipe(prompt, max_new_tokens=256, do_sample=False)[0][\"generated_text\"]\n",
        "    parsed = parse_llm_output(raw)\n",
        "\n",
        "    if not parsed:\n",
        "        return None\n",
        "\n",
        "    # normalize to RM billions where possible\n",
        "    for k in [\"exports\", \"imports\", \"trade_balance\", \"total_trade\"]:\n",
        "        parsed[k] = coerce_billion(parsed.get(k))\n",
        "    parsed.update({\"file\": fname, \"method\": \"llm_only\", \"text_len\": len(txt)})\n",
        "    return parsed\n"
      ],
      "metadata": {
        "id": "GxbzmfArfv5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Batch run over inputs/ and save CSV ---\n",
        "pdfs = sorted(INPUT_DIR.rglob(\"*.pdf\"))\n",
        "results = []\n",
        "for p in pdfs:\n",
        "    r = extract_llm_only(p)\n",
        "    if r: results.append(r)\n",
        "    gc.collect()\n",
        "\n",
        "df_pred = pd.DataFrame(results)\n",
        "pred_csv = OUT_DIR / \"llm_zephyr7b_extraction.csv\"\n",
        "df_pred.to_csv(pred_csv, index=False)\n",
        "pred_csv\n"
      ],
      "metadata": {
        "id": "KYFMWlLPfzDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Benchmark against sample ground truth ---\n",
        "if GT_CSV.exists() and not df_pred.empty:\n",
        "    gt = pd.read_csv(GT_CSV)\n",
        "    # try to align on filename column\n",
        "    key = next((c for c in [\"file\",\"filename\",\"Source_File\",\"PDF_Name\",\"PDF\"] if c in gt.columns), None)\n",
        "    if key is None:\n",
        "        raise ValueError(\"Ground truth CSV must include a filename column.\")\n",
        "\n",
        "    merged = pd.merge(df_pred, gt, left_on=\"file\", right_on=key, how=\"left\", suffixes=(\"\",\"_true\"))\n",
        "\n",
        "    # compute metrics table if *_true exist\n",
        "    keep = [\"exports\",\"imports\",\"trade_balance\",\"total_trade\"]\n",
        "    have_truth = [k for k in keep if f\"{k}_true\" in merged.columns]\n",
        "    if have_truth:\n",
        "        table = metrics_table(merged, have_truth)\n",
        "        display(table)\n",
        "        out_bench = OUT_DIR / \"llm_benchmark_comparison.csv\"\n",
        "        merged.to_csv(out_bench, index=False)\n",
        "        out_bench\n"
      ],
      "metadata": {
        "id": "4WQxvGjtf1py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ Notes\n",
        "- This demo favors **clarity and portability** over maximum accuracy.\n",
        "- Full thesis notebooks (data wrangling, advanced prompts, hybrid regex+LLM) remain private.\n"
      ],
      "metadata": {
        "id": "zwDv1VUqf8fG"
      }
    }
  ]
}
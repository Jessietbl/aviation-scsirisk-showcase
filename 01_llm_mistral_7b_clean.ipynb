{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6FxfPOMc9WAxftO7pvYfh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jessietbl/aviation-scsirisk-showcase/blob/main/01_llm_mistral_7b_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM-based Trade Data Extraction (Mistral-7B) — Showcase\n",
        "\n",
        "This demo extracts **monthly trade statistics** (exports, imports, trade_balance, total_trade) from Malaysian trade bulletins.\n",
        "\n",
        "**What’s inside**\n",
        "1) Load PDFs from `inputs/`  \n",
        "2) Extract & clean text  \n",
        "3) Prompt Mistral-7B for JSON  \n",
        "4) Parse + (optionally) benchmark vs ground truth\n",
        "\n",
        "> Uses **sample PDFs / sample GT** only. Full thesis data/code remain private.\n"
      ],
      "metadata": {
        "id": "ZrU_M4UEfj5e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6W2L3wlfb6r"
      },
      "outputs": [],
      "source": [
        "# --- 0. Imports & Config (portable: no !pip, no Colab APIs) ---\n",
        "from pathlib import Path\n",
        "import os, re, json, glob, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pdfplumber\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "from src.utils import (\n",
        "    preprocess_text,\n",
        "    build_llm_prompt,\n",
        "    parse_llm_output,\n",
        "    coerce_billion,\n",
        "    metrics_table\n",
        ")\n",
        "\n",
        "INPUT_DIR = Path(\"inputs\")          # put sample PDFs here\n",
        "OUT_DIR   = Path(\"outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "GT_CSV    = Path(\"data/sample_ground_truth.csv\")  # optional benchmark\n",
        "MODEL_ID  = \"mistralai/Mistral-7B-Instruct-v0.1\"  # keep as-is for clarity\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. PDF → text (OCR fallback) ---\n",
        "MONTH_RE = re.compile(\n",
        "    r\"\\b(January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4}\\b\",\n",
        "    flags=re.I\n",
        ")\n",
        "\n",
        "def extract_text_enhanced(path: Path, max_pages: int = 6) -> str:\n",
        "    \"\"\"\n",
        "    Extract text from first few content pages; fallback to OCR when needed.\n",
        "    Filters to pages that likely mention the current month.\n",
        "    \"\"\"\n",
        "    text = []\n",
        "    with pdfplumber.open(path) as pdf:\n",
        "        pages = pdf.pages[1:max_pages+1] if len(pdf.pages) > 1 else pdf.pages\n",
        "        for idx, page in enumerate(pages, start=2):\n",
        "            raw = page.extract_text() or \"\"\n",
        "            if len(raw.strip()) < 60 or (\"export\" not in raw.lower() and \"trade\" not in raw.lower()):\n",
        "                try:\n",
        "                    image = page.to_image(resolution=300).original\n",
        "                    raw = pytesseract.image_to_string(image, lang=\"eng\", config=\"--psm 6 --oem 3\")\n",
        "                except Exception:\n",
        "                    raw = \"\"\n",
        "            if raw and MONTH_RE.search(raw):\n",
        "                text.append(f\"\\n--- PAGE {idx} ---\\n{raw}\")\n",
        "\n",
        "        # fallback: if nothing caught the month, just append raw text\n",
        "        if not \"\".join(text).strip():\n",
        "            for idx, page in enumerate(pages, start=2):\n",
        "                raw = page.extract_text() or \"\"\n",
        "                if raw:\n",
        "                    text.append(f\"\\n--- PAGE {idx} ---\\n{raw}\")\n",
        "\n",
        "    return preprocess_text(\"\\n\".join(text))[:8000]\n"
      ],
      "metadata": {
        "id": "Pkt3upcefoJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Load Mistral-7B (4-bit optional to keep VRAM small) ---\n",
        "def load_llm(model_id: str = MODEL_ID):\n",
        "    qconf = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=\"bfloat16\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "    )\n",
        "    tok = AutoTokenizer.from_pretrained(model_id)\n",
        "    tok.pad_token = tok.eos_token\n",
        "    mdl = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id, device_map=\"auto\", quantization_config=qconf, trust_remote_code=True\n",
        "    )\n",
        "    return pipeline(\n",
        "        \"text-generation\",\n",
        "        model=mdl,\n",
        "        tokenizer=tok,\n",
        "        return_full_text=False,\n",
        "        pad_token_id=tok.eos_token_id,\n",
        "    )\n",
        "\n",
        "pipe = load_llm()\n"
      ],
      "metadata": {
        "id": "BtRtZHhsfsRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Single-file extraction (PDF → text → LLM JSON → dict) ---\n",
        "def extract_llm_only(pdf_path: Path) -> dict | None:\n",
        "    fname = pdf_path.name\n",
        "    txt = extract_text_enhanced(pdf_path)\n",
        "    if not txt or len(txt) < 120:\n",
        "        return None\n",
        "\n",
        "    prompt = build_llm_prompt(txt, fname)\n",
        "    raw = pipe(prompt, max_new_tokens=256, do_sample=False)[0][\"generated_text\"]\n",
        "    parsed = parse_llm_output(raw)\n",
        "\n",
        "    if not parsed:\n",
        "        return None\n",
        "\n",
        "    # normalize to RM billions where possible\n",
        "    for k in [\"exports\", \"imports\", \"trade_balance\", \"total_trade\"]:\n",
        "        parsed[k] = coerce_billion(parsed.get(k))\n",
        "    parsed.update({\"file\": fname, \"method\": \"llm_only\", \"text_len\": len(txt)})\n",
        "    return parsed\n"
      ],
      "metadata": {
        "id": "GxbzmfArfv5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Batch run over inputs/ and save CSV ---\n",
        "pdfs = sorted(INPUT_DIR.rglob(\"*.pdf\"))\n",
        "results = []\n",
        "for p in pdfs:\n",
        "    r = extract_llm_only(p)\n",
        "    if r: results.append(r)\n",
        "    gc.collect()\n",
        "\n",
        "df_pred = pd.DataFrame(results)\n",
        "pred_csv = OUT_DIR / \"llm_only_extraction.csv\"\n",
        "df_pred.to_csv(pred_csv, index=False)\n",
        "pred_csv\n"
      ],
      "metadata": {
        "id": "KYFMWlLPfzDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Benchmark against sample ground truth ---\n",
        "if GT_CSV.exists() and not df_pred.empty:\n",
        "    gt = pd.read_csv(GT_CSV)\n",
        "    # try to align on filename column\n",
        "    key = next((c for c in [\"file\",\"filename\",\"Source_File\",\"PDF_Name\",\"PDF\"] if c in gt.columns), None)\n",
        "    if key is None:\n",
        "        raise ValueError(\"Ground truth CSV must include a filename column.\")\n",
        "\n",
        "    merged = pd.merge(df_pred, gt, left_on=\"file\", right_on=key, how=\"left\", suffixes=(\"\",\"_true\"))\n",
        "\n",
        "    # compute metrics table if *_true exist\n",
        "    keep = [\"exports\",\"imports\",\"trade_balance\",\"total_trade\"]\n",
        "    have_truth = [k for k in keep if f\"{k}_true\" in merged.columns]\n",
        "    if have_truth:\n",
        "        table = metrics_table(merged, have_truth)\n",
        "        display(table)\n",
        "        out_bench = OUT_DIR / \"llm_benchmark_comparison.csv\"\n",
        "        merged.to_csv(out_bench, index=False)\n",
        "        out_bench\n"
      ],
      "metadata": {
        "id": "4WQxvGjtf1py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ Notes\n",
        "- This demo favors **clarity and portability** over maximum accuracy.\n",
        "- Full thesis notebooks (data wrangling, advanced prompts, hybrid regex+LLM) remain private.\n"
      ],
      "metadata": {
        "id": "zwDv1VUqf8fG"
      }
    }
  ]
}